{
  "phase": "Phase 1.8: Hardened Autonomous Loop & Advanced Remediation",
  "phase_goal": "Significantly improve the robustness and self-correction capabilities of the autonomous workflow loop based on real-world failure analysis, incorporating learning from failures, more sophisticated remediation, and better error handling.",
  "success_metrics": [
    "The Workflow Driver successfully handles and remediates common syntax, style, ethical, and test failures autonomously.",
    "Critical errors (like IndentationError) are caught and addressed at the step level before writing.",
    "Automated tests are executed after code modification steps.",
    "The remediation loop successfully fixes >= 85% of tasks that fail initial validation (excluding fundamental design/ambiguity issues).",
    "The Grade Report clearly distinguishes validation execution errors from findings and highlights critical issues.",
    "Detailed failure data is logged and stored for learning and analysis.",
    "The system can attempt to decompose complex tasks into smaller sub-tasks.",
    "Code merging is more robust and less likely to introduce syntax errors.",
    "The system can predict the likelihood of autonomous success for a task.",
    "Phase 1.8 tests achieve >= 95% code coverage for new logic."
  ],
  "tasks": [
    {
      "task_id": "task_1_8_1_pre_fix",
      "priority": "Critical",
      "task_name": "Refine Step Classification to Correctly Identify Research Steps",
      "description": "Modify WorkflowDriver's step classification logic to ensure that plan steps primarily involving 'Research and identify', 'Analyze', or 'Investigate' are not classified as code generation steps, even if they mention target files or code-related keywords as examples. This is a prerequisite to allow the main task_1_8_1 to proceed autonomously.",
      "status": "Completed",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": []
    },
    {
      "task_id": "task_1_8_0_fix_summarizer_synthesize",
      "priority": "Critical",
      "task_name": "Fix AttributeError in RecursiveSummarizer for synthesize method",
      "description": "The EnhancedLLMOrchestrator calls self.summarizer.synthesize(), but RecursiveSummarizer does not have this method. Add a synthesize(self, summaries: List[str]) -> str method to RecursiveSummarizer in src/core/chunking/recursive_summarizer.py that joins the list of summaries into a single string. This is needed to unblock code generation in _handle_large_context.",
      "status": "Completed",
      "target_file": "src/core/chunking/recursive_summarizer.py",
      "depends_on": [
        "task_1_8_1_pre_fix"
      ]
    },
    {
      "task_id": "task_1_8_0_fix_token_allocator",
      "priority": "Critical",
      "task_name": "Adjust TokenAllocator Cost Function for Realistic Allocations",
      "description": "The TokenAllocator's cost function _model_cost in src/core/optimization/adaptive_token_allocator.py has a quadratic term that heavily penalizes token count, resulting in minimal allocations (e.g., 101 tokens). Modify the coefficient of the quadratic term (e.g., change the divisor from 1000.0 to 10000000.0) to allow for more realistic token allocations for code generation tasks. Also, ensure the solver is reset before each allocation call.",
      "status": "Completed",
      "target_file": "src/core/optimization/adaptive_token_allocator.py",
      "depends_on": [
        "task_1_8_0_fix_summarizer_synthesize"
      ]
    },
    {
      "task_id": "task_1_8_1_unblock_overwrite_fix",
      "priority": "Critical",
      "task_name": "Prevent Placeholder Overwrite of Core Python Files for Conceptual Steps",
      "description": "Modify the WorkflowDriver's autonomous_loop logic. Specifically, in the 'explicit file writing' branch, add a condition to prevent writing placeholder content to the main Python target_file of a task if the plan step is conceptual (e.g., 'define a list', 'analyze requirements') and not an explicit 'create file' or 'generate file' instruction. Also, ensure Python-specific placeholders (#) are used if a placeholder write to a .py file is genuinely intended.",
      "status": "Completed",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_1_pre_fix",
        "task_1_8_0_fix_summarizer_synthesize",
        "task_1_8_0_fix_token_allocator"
      ]
    },
    {
      "task_id": "task_1_8_1_fix_syntax_and_add_tests",
      "priority": "Critical",
      "task_name": "Fix Syntax Error in classify_plan_step and Add Unit Tests",
      "description": "The code generated for task_1_8_1 (Enhance Plan Step Identification) included an erroneous trailing line causing a syntax/name error. Remove this line from src/core/automation/workflow_driver.py. Additionally, create comprehensive unit tests for the new classify_plan_step function. Tests should cover code steps, conceptual steps, ambiguous steps, and edge cases. Place tests in tests/test_phase1_8_features.py.",
      "status": "Completed",
      "target_file": "src/core/automation/workflow_driver.py, tests/test_phase1_8_features.py",
      "depends_on": [
        "task_1_8_1_unblock_overwrite_fix"
      ]
    },
    {
      "task_id": "task_1_8_1",
      "priority": "Critical",
      "task_name": "Enhance Plan Step Identification",
      "description": "Improve the Workflow Driver's logic to better identify plan steps requiring code modification (imports, constants, definitions, etc.) vs. conceptual steps. Use more sophisticated keyword matching or NLP.",
      "status": "Completed",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_1_fix_syntax_and_add_tests"
      ]
    },
    {
      "task_id": "task_1_8_1b_increase_min_token_alloc",
      "priority": "Critical",
      "task_name": "Increase Minimum Token Allocation per Chunk",
      "description": "Modify TokenAllocator and EthicalAllocationPolicy to enforce a higher minimum token count per chunk (e.g., 1000 tokens instead of 100). This is crucial for effective code generation, as the current minimum leads to insufficient token allocation and stalls progress on code-generating tasks. This task addresses the shortcomings of task_1_8_0_fix_token_allocator.",
      "status": "Completed",
      "target_file": "src/core/optimization/adaptive_token_allocator.py, src/core/ethics/constraints.py",
      "depends_on": [
        "task_1_8_1"
      ]
    },
    {
      "task_id": "task_1_8_2b_fix_placeholder_overwrite_for_modification_steps",
      "priority": "Critical",
      "task_name": "Refine Placeholder Write Logic for Main Target Modification",
      "description": "Modify WorkflowDriver.autonomous_loop to prevent placeholder overwrites on the main Python task_target_file for steps that imply modification rather than creation (e.g., \"insert a block\", \"add logic to method X\"). Such steps, if classified as 'explicit file writing', should be treated as code generation steps or have their placeholder write skipped entirely if they are too vague for direct code generation. This refines task_1_8_1_unblock_overwrite_fix. Add unit tests for this specific logic in tests/test_phase1_8_features.py, covering scenarios where placeholders should and should not be written to the main Python target.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py, tests/test_phase1_8_features.py",
      "depends_on": []
    },
    {
      "task_id": "task_1_8_2c_target_test_file_for_test_writing_steps",
      "priority": "Critical",
      "task_name": "Correctly Target Test Files for Unit Test Generation Steps",
      "description": "Enhance WorkflowDriver.autonomous_loop step processing. If a plan step is for writing unit tests (e.g., contains \"write unit tests for X\", mentions tests/test_*.py, or filepath_from_step points to a test file path), ensure the generated test code is written to the appropriate test file path. This path should be derived from filepath_from_step if valid and test-like, or by convention from task_target_file (e.g., src/A.py -> tests/test_A.py). This determined test file path should override task_target_file for the write operation if task_target_file is not itself a test file. Add unit tests for this file targeting logic in tests/test_phase1_8_features.py.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py, tests/test_phase1_8_features.py",
      "depends_on": [
        "task_1_8_2b_fix_placeholder_overwrite_for_modification_steps"
      ]
    },
    {
      "task_id": "task_1_8_2_retry",
      "priority": "Critical",
      "task_name": "Implement Pre-Write Validation per Step (Retry)",
      "description": "Add logic to the Workflow Driver to run basic syntax, style, and ethical checks on generated code snippets *before* merging and writing to the target file. Use CodeReviewAgent and EthicalGovernanceEngine. This is a retry of the original task_1_8_2.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_2c_target_test_file_for_test_writing_steps"
      ]
    },
    {
      "task_id": "task_1_8_3",
      "priority": "Critical",
      "task_name": "Implement Step-Level Remediation Loop",
      "description": "If pre-write validation fails, provide targeted feedback to the Coder LLM and retry generating the snippet for that specific step (e.g., 2-3 attempts) before failing the step or task.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_2_retry"
      ]
    },
    {
      "task_id": "task_1_8_4",
      "priority": "Critical",
      "task_name": "Ensure Post-Write, Step-Level Test Execution",
      "description": "Modify the Workflow Driver to automatically trigger relevant tests (using execute_tests) after any plan step that successfully modifies code, especially if the task has a target_file that implies testability (e.g., .py file). Capture results in _current_task_results.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_3"
      ]
    },
    {
      "task_id": "task_1_8_5",
      "priority": "High",
      "task_name": "Implement Learning from Failures (Data Capture)",
      "description": "Log detailed information about validation failures, remediation attempts, LLM prompts/responses, and outcomes. Store this structured data in the Knowledge Graph or a dedicated database for analysis and learning.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_4"
      ]
    },
    {
      "task_id": "task_1_8_14",
      "priority": "High",
      "task_name": "Address Ethical Debt in Token Allocator Policy",
      "description": "The temporary fix for AllocationError in EthicalAllocationPolicy bypassed diversity constraints. Implement a robust, ethical token allocation strategy that correctly handles large prompts and multiple chunks, potentially revising Z3 constraints or exploring alternative allocation methods. Ensure the policy promotes model diversity where feasible without causing allocation failures.",
      "status": "Not Started",
      "target_file": "src/core/ethics/constraints.py, src/core/optimization/adaptive_token_allocator.py",
      "depends_on": [
        "task_1_8_1",
        "task_1_8_6"
      ]
    },
    {
      "task_id": "task_1_8_7",
      "priority": "Medium",
      "task_name": "Implement Automated Task Decomposition",
      "description": "Add logic to the Workflow Driver or a Planning Agent to assess task complexity and automatically break down large tasks into smaller, dependent sub-tasks in the roadmap if needed.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_1",
        "task_1_8_5"
      ]
    },
    {
      "task_id": "task_1_8_8",
      "priority": "Medium",
      "task_name": "Refine Grade Report & Error Logging",
      "description": "Update generate_grade_report to clearly distinguish validation execution errors from findings and highlight critical issues. Improve overall logging clarity for debugging autonomous runs.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_5"
      ]
    },
    {
      "task_id": "task_1_8_9",
      "priority": "High",
      "task_name": "Implement Advanced Code Merging",
      "description": "Replace the current string-based _merge_snippet with an AST-aware merging utility to handle code modifications more robustly and reduce the chance of introducing syntax errors during merging.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_3"
      ]
    },
    {
      "task_id": "task_1_8_10",
      "priority": "High",
      "task_name": "Implement Prompt Self-Correction Mechanism",
      "description": "If remediation attempts fail for a step, analyze the failure and modify the *prompt* sent to the Coder LLM for the next attempt, or potentially modify the original code generation prompt template based on failure patterns.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_3",
        "task_1_8_5",
        "task_1_8_6"
      ]
    },
    {
      "task_id": "task_1_8_11",
      "priority": "High",
      "task_name": "Improve Coder LLM Prompt Generation Logic",
      "description": "Refine how the Workflow Driver constructs prompts for the Coder LLM, incorporating lessons learned from failure data (task_1_8_5) and successful prompt self-correction (task_1_8_10).",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_5",
        "task_1_8_10"
      ]
    },
    {
      "task_id": "task_1_8_12",
      "priority": "Medium",
      "task_name": "Implement Task Success Prediction",
      "description": "Develop a simple model (potentially using data from task_1_8_5) to predict the likelihood of autonomous success for a given task based on its characteristics. Use this to inform task selection or flag low-probability tasks for manual review.",
      "status": "Not Started",
      "target_file": "src/core/automation/workflow_driver.py",
      "depends_on": [
        "task_1_8_5"
      ]
    },
    {
      "task_id": "task_1_8_13",
      "priority": "High",
      "task_name": "Add Comprehensive Tests for Phase 1.8 Features",
      "description": "Write comprehensive unit/integration tests covering all new features in Phase 1.8, including pre-write validation, step-level retries, post-write test execution, improved remediation logic, failure data capture, task decomposition, advanced merging, prompt self-correction, improved prompt generation, and task success prediction.",
      "status": "Not Started",
      "target_file": "tests/test_phase1_8_features.py",
      "depends_on": [
        "task_1_8_1",
        "task_1_8_2_retry",
        "task_1_8_3",
        "task_1_8_4",
        "task_1_8_5",
        "task_1_8_6",
        "task_1_8_7",
        "task_1_8_8",
        "task_1_8_9",
        "task_1_8_10",
        "task_1_8_11",
        "task_1_8_12"
      ]
    }
  ],
  "next_phase_actions": [
    "Set `status`: `Completed` on all Phase 1.8 tasks.",
    "Update the `phase`, `phase_goal`, and `current_focus` fields to 'Phase 2 Iteration 2: Enhanced Agents & Knowledge Graph'."
  ],
  "current_focus": "\ud83c\udfaf CURRENT FOCUS: Phase 1.8 - Hardened Autonomous Loop & Advanced Remediation \ud83d\udee0\ufe0f"
}
# .env.example

# Optional LLM settings
LLM_MAX_RETRIES=3
LLM_TIMEOUT=30

# Required: Get your API key from https://ai.google.dev/
LLM_PROVIDER=gemini
GEMINI_API_KEY=your_key_here
GEMINI_MODEL=gemini-2.5-flash-lite-preview-06-17
YOUR_GITHUB_API_KEY=your_github_token
HUGGING_FACE_API_KEY=your_hf_api_key
ZAP_API_KEY=your_zap_api_key
DOCKERHUB_USERNAME=your_dockerhub_username
HUGGING_FACE_MODEL=Qwen/Qwen3-235B-A22B
ENABLE_HUGGING_FACE=false # Set to true to enable Hugging Face models

# System configuration
SAFETY_MARGIN=5
QUANTUM_DEPTH=3
ETHICAL_THRESHOLD=90

PYTHONPATH=./src

# Redis URL for Flask-Limiter (used by docker-compose and dev_run.py)
REDIS_URL=redis://redis:6379